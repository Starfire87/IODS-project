M<-matrix(c(1:5),nrow=5,ncol=5)
M
M<-t(M)
M
M<-t(matrix(c(1:5),nrow=5,ncol=5))
M
Y<-add.Gaussian.noise(M,mean=0,stddev=1,symm=TRUE)
M
Y<-rnorm(X,mean=0,sd=1)
Y<-rnorm(25,mean=0,sd=1)+M
Y
Z<-aov(y~A,data=Y)
Z<-as.data.frame(Y)
Z
A<-aov(V1~V2+V3+V4+V5,Z)
A
summary(A)
levels(Z)
anova(Z)
anova(Y)
A<-anova(V1~V2+V3+V4+V5,Z)
mean(count["V1"])
mean(Z["V1"])
tapply(Z$V1,mean)
mean(Z$V1)
boxplot(Z$V1~Z$V2)
boxplot(Z$V1~Z$V2+Z$V3)
boxplot(Z$V1~Z$V2+Z$V3+Z$V4)
means(Z$V1,Z$V2,Z$V3)
tapply(Z$V1,Z$V2,Z$V3,mean)
mean(Z$V1,Z$V2,Z$V3)
aov(Z$V1~Z$V2)
A<-aov(Z$V1~Z$V2)
summary(A)
A<-aov(Z$V1~Z$V2+Z$V3+Z$V4+Z$V5)
A
summary(A)
str(Z)
ggboxplot(Z)
A<-aov(V1~V2*V3*V4*V5,Z)
A
summary(A)
levels(Z$V1)
grouping(Z)
drugs<-data.frame(P=c(20.5,21.8,17.7,20.9,20.3),LD=c(9.2,10.1,10.8,14.1,13.3),HD=c(8.2,12.5,10.2,9.4,10.2))
drugs
aov(P~LD*HD,data=drugs)
drugs.aov<-aov(P~LD*HD,data=drugs)
summary(drugs.aov)
summary(aov(P~HD,data=drugs))
summary(aov(HD~LD*P,data=drugs))
boxplot(drugs$P~drugs$LD*drugs$HD)
summary(aov(P~LD,data=drugs))
summary(aov(HD~LD,data=drugs))
drugs<-data.frame(drug=c("P"*5,LD*5,HD*5),condition=c(20.5,21.8,17.7,20.9,20.3,9.2,10.1,10.8,14.1,13.3,8.2,12.5,10.2,9.4,10.2))
drugs<-data.frame(drug=c("P","P","P","P","P","LD","LD","LD","LD","LD","HD","HD","HD","HD","HD"),condition=c(20.5,21.8,17.7,20.9,20.3,9.2,10.1,10.8,14.1,13.3,8.2,12.5,10.2,9.4,10.2))
drugs
summary(aov(drug~condition,data=drugs))
summary(aov(condition~drug,data=drugs))
Z
anova(z)
anova(Z)
summary(aov(condition~drug,data=drugs))
drugs.aov<-aov(condition~drug,data=drugs)
summary(drugs.aov,expand.split=TRUE)
summary(drugs.aov,split(drugs,drugs$drug))
boxplot(condition~drug,data=drugs)
pairwise.t.test(drugs$condition,drugs$drug,p.adjust="bonferroni")
anova(lm(drugs$condition~drugs$drug))
anova(lm(Z$V1~Z$V2*Z$V3*Z$V4*Z$V5))
summary(drugs.aov[,"Sum Sq"])
Y
a<-c(Y[1,],Y[2,],Y[3,],Y[4,],Y[5,])
a
a<-c(Y[1,],Y[2,],Y[3,],Y[,4],Y[,5])
a<-c(Y[,1],Y[,2],Y[,3],Y[,4],Y[,5])
a
b<-c(rep("V1",5),rep("V2",5),rep("V3",5),rep("V4",5),rep("V5",5))
b
data<-data.frame(val=a,group=b)
data
summary(aov(val~group,data=data))
val.aov<-aov(val~group,data=data)
pairwise.t.test(data$val,data$group,p.adjust="bonferroni")
drugs<-data.frame(drug=c(rep(“P”,5),rep("LD",5),rep(“HD",5)),condition=c(20.5,21.8,17.7,20.9,20.3,9.2,10.1,10.8,14.1,13.3,8.2,12.5,10.2,9.4,10.2))
drugs<-data.frame(drug=c(rep("P",5),rep("LD",5),rep("HD",5)),condition=c(20.5,21.8,17.7,20.9,20.3,9.2,10.1,10.8,14.1,13.3,8.2,12.5,10.2,9.4,10.2))
drugs<-data.frame(drug=c(rep("P",5),rep("LD",5),rep("HD",5)),condition=c(20.5,21.8,17.7,20.9,20.3,9.2,10.1,10.8,14.1,13.3,8.2,12.5,10.2,9.4,10.2))
summary(aov(condition~drug,data=drugs))
summary(drugs.aov<-aov(condition~drug,data=drugs))
TukeyHSD(drugs.aov, drugs$drug, ordered=TRUE)
TukeyHSD(drugs.aov, "P", ordered=TRUE)
TukeyHSD(drugs.aov, "drug", ordered=TRUE)
drugs<-data.frame(drug=c("A","B","C","D","E"),sleep=c(6.13,7.21,7.14,6.91,6.94))
summary(drug.aov<-aov(sleep~drug,data=drugs))
TukeyHSD(drugs.aov, "drug", ordered=TRUE)
TukeyHSD(drug.aov, "drug", ordered=TRUE)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
dim(lrn14)
str(lrn14)
# Access the dplyr library
library(dplyr)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
install.packages("dplyr")
#Reading the data into variable lrn14
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
#Exploring the structure and dimensions of the data
dim(lrn14)
# create column 'attitude' by scaling the column "Attitude"
lrn14$attitude <- lrn14$Attitude / 10
# Access the dplyr library
library(dplyr)
# Kristiina Suominen
# 7.11.2018
# Regression and model validation
installed.packages()
# Kristiina Suominen
# 7.11.2018
# Regression and model validation
install.packages(pkgs="plyr")
# Access the dplyr library
library(dplyr)
install.packages("dplyr")
# Access the dplyr library
library("dplyr")
#Reading the data into variable lrn14
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
#Exploring the structure and dimensions of the data
dim(lrn14)
str(lrn14)
# create column 'attitude' by scaling the column "Attitude"
lrn14$attitude <- lrn14$Attitude / 10
# Access the dplyr library
library("dplyr")
install.packages("dplyr", dependencies = TRUE)
# Access the dplyr library
library(dplyr)
install.packages("dplyr")
# Access the dplyr library
library(dplyr)
# Access the dplyr library
library("dplyr")
# Accessing the dplyr library
library(dplyr)
install.packages("dplyr")
#Reading the data into variable lrn14
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
installed.packages()
install.packages("dplyr")
#Reading the data into variable lrn14
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)#Exploring the structure and dimensions of the data
# creating column 'attitude' by scaling the column "Attitude"
lrn14$attitude <- lrn14$Attitude / 10
# Accessing the dplyr library
library(dplyr)
# Selecting questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# selecting the columns related to deep learning and creating column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# selecting the columns related to surface learning and creating column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# selecting the columns related to strategic learning and creating column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# choosing the columns to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# selecting the 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# see the stucture of the new dataset
str(learning2014)
# select rows where points is greater than zero
learning2014 <- filter(learning2014, points > 0)
# select rows where points is greater than zero
learning2014 <- filter(lrn14, points > 0)
#Reading the data into variable lrn14
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)#Exploring the structure and dimensions of the data
# creating column 'attitude' by scaling the column "Attitude"
lrn14$attitude <- lrn14$Attitude / 10
# Accessing the dplyr library
library(dplyr)
# Selecting questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# selecting the columns related to deep learning and creating column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# selecting the columns related to surface learning and creating column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# selecting the columns related to strategic learning and creating column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# choosing the columns to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# selecting the 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# select rows where points is greater than zero
learning2014 <- filter(lrn14, points > 0)
# select rows where points is greater than zero
learning2014 <- filter(learning2014, points > 0)
# see the stucture of the new dataset
str(learning2014)
# select rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
setwd("~/GitHub/IODS-project")
#Saving the analysis dataset
write.csv(learning2014, file = "learning2014.csv")
